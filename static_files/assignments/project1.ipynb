{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMfLrTH4aGl2"
   },
   "source": [
    "# DS 542 Fall 2025 Project 1\n",
    "\n",
    "Your task for this project to train a better model for the Tree-or-Not data set.\n",
    "Your model will be constrained to use the architecture in this template.\n",
    "To train a better model, you will instead practice picking appropriate initializations and regularizations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VSeZuv0_8qe"
   },
   "source": [
    "## Background\n",
    "\n",
    "This notebook builds a model detecting trees in images.\n",
    "The data set is available on GitHub at https://github.com/DL4DS/tree-or-not or on the Shared Compute Cluster at `/projectnb/ds542/materials/tree-or-not`.\n",
    "The initial data set consists of roughly 500 pictures.\n",
    "Most of them are from the Boston area, but some are from around the globe.\n",
    "Most of them were taken outside, but some were taken inside or in more exotic locations.\n",
    "Many other factors such as lighting, weather, and confounding bushes will make this a challenging problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "1. Run the provided notebook and confirm basic functionality.\n",
    "2. Pick, describe and demonstrate a training improvement in each of the following categories - early stopping, initialization, learning rate, and other regularization. (40%)\n",
    "3. Train models with all 16 combinations of the previous 4 choices and plot their training progress. (10%)\n",
    "4. In one week (10/13), a new validation set will be posted. Show the accuracy of your 16 models on this new validation data.\n",
    "6. Explain as best you can why each improvement was included or not included in the best performing model. (20%)\n",
    "5. Save the best performing model for further evaluation by the auto-grader. (30%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BewCY6YI_sMk"
   },
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically add location of class packages if running on the SCC\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "scc_site_packages = \"/projectnb/ds542/materials/lib/python3.12/site-packages\"\n",
    "if os.path.isdir(scc_site_packages) and scc_site_packages not in sys.path:\n",
    "    sys.path.append(scc_site_packages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y5hXzVgnaGl9"
   },
   "outputs": [],
   "source": [
    "import imageio.v2 as imageio\n",
    "import livelossplot\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torcheval.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAN0vdTd_sMm"
   },
   "source": [
    "## GPU Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QW0hW-araGl-"
   },
   "outputs": [],
   "source": [
    "def to_gpu(t):\n",
    "    if torch.cuda.is_available():\n",
    "        return t.cuda()\n",
    "    return t\n",
    "\n",
    "def to_numpy(t):\n",
    "    return t.detach().cpu().numpy()\n",
    "\n",
    "device = to_gpu(torch.ones(1,1)).device\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mh9aFl5f_sMn"
   },
   "source": [
    "## Load Data\n",
    "\n",
    "If you are not running on the SCC, fetch the data from https://github.com/dl4ds/tree-or-not as needed.\n",
    "For example, you could use `git clone` to make a local copy and update `data_dir` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLnleFagaGmA"
   },
   "outputs": [],
   "source": [
    "image_width = 256 # DO NOT CHANGE\n",
    "data_dir = \"/projectnb/ds542/materials/tree-or-not\"\n",
    "\n",
    "def load_data_set(data_set_name):\n",
    "    labels = pd.read_csv(f\"{data_dir}/{data_set_name}.tsv\", sep=\"\\t\")\n",
    "\n",
    "    file_names = []\n",
    "    images = []\n",
    "    targets = []\n",
    "    for i in range(labels.shape[0]):\n",
    "        row = labels.iloc[i]\n",
    "        try:\n",
    "            image = imageio.imread(f\"{data_dir}/images{image_width}/{row['filename']}\")[...]\n",
    "        except:\n",
    "            print(\"SKIPPING \", row['filename'], \"MISSING\")\n",
    "            continue\n",
    "\n",
    "        if image.shape[0] != image.shape[1] * 3 // 4:\n",
    "            print(\"SKIPPING \", row['filename'], image.shape)\n",
    "            continue\n",
    "\n",
    "        # convert from 0-255 to 0.0-1.0\n",
    "        image = image / 255\n",
    "        # prepend axis with length one\n",
    "        # image = image.reshape(1, *image.shape)\n",
    "        image = torch.tensor(image, device=device, dtype=torch.float32)\n",
    "        # permute image dimensions to put color channel first\n",
    "        image = torch.permute(image, [2, 0, 1])\n",
    "\n",
    "        file_names.append(row['filename'])\n",
    "        images.append(image)\n",
    "        targets.append(row[\"target\"])\n",
    "\n",
    "    images = torch.stack(images)\n",
    "\n",
    "    targets = torch.tensor(targets, device=device, dtype=torch.float32)\n",
    "    targets = targets.long()\n",
    "\n",
    "    return (file_names, images, targets)\n",
    "\n",
    "train_data_set = load_data_set(\"train\")\n",
    "for t in train_data_set[1:]:\n",
    "    print(\"TRAIN\", t.shape, t.dtype, t.device)\n",
    "(train_file_names, train_X, train_Y) = train_data_set\n",
    "\n",
    "validation_data_set = load_data_set(\"validation\")\n",
    "for t in validation_data_set[1:]:\n",
    "    print(\"VALIDATION\", t.shape, t.dtype, t.device)\n",
    "(validation_file_names, validation_X, validation_Y) = validation_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fIXCLGqaGmB"
   },
   "outputs": [],
   "source": [
    "plt.imshow(to_numpy(torch.permute(train_X[0,:,:,:], (1, 2, 0))));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-zXXZ4maGl_"
   },
   "source": [
    "## Model Building\n",
    "\n",
    "Do not modify any of this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRFJ7RrBaGmB"
   },
   "outputs": [],
   "source": [
    "class TreeNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_0 = torch.nn.Conv2d(in_channels=3, out_channels=5, kernel_size=5, stride=2, device=device)\n",
    "        self.conv_1 = torch.nn.Conv2d(in_channels=5, out_channels=5, kernel_size=5, stride=2, device=device)\n",
    "        self.conv_2 = torch.nn.Conv2d(in_channels=5, out_channels=5, kernel_size=5, stride=2, device=device)\n",
    "        self.conv_3 = torch.nn.Conv2d(in_channels=5, out_channels=5, kernel_size=5, stride=2, device=device)\n",
    "        self.fc_3 = torch.nn.Linear(585, 2)\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        X = self.conv_0(X)\n",
    "        X = self.relu(X)\n",
    "\n",
    "        X = self.conv_1(X)\n",
    "        X = self.relu(X)\n",
    "\n",
    "        X = self.conv_2(X)\n",
    "        X = self.relu(X)\n",
    "\n",
    "        X = self.conv_3(X)\n",
    "        X = self.relu(X)\n",
    "\n",
    "        # flatten channels and image dimensions\n",
    "        X = X.reshape(X.shape[:-3] + (-1,))\n",
    "\n",
    "        X = self.fc_3(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "test_model = TreeNetwork().to(device)\n",
    "test_output = test_model(train_X[:5,:,:,:])\n",
    "assert test_output.shape == (5, 2)\n",
    "del test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqGF4li0aGmC"
   },
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oByjz-RSaGmC"
   },
   "outputs": [],
   "source": [
    "DEFAULT_EPOCHS = 1000 if torch.cuda.is_available() else 100\n",
    "\n",
    "def train_model(model_class, epochs=DEFAULT_EPOCHS, learning_rate=1e-4, **kwargs):\n",
    "    model = model_class(**kwargs)\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    liveloss = livelossplot.PlotLosses()\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        prediction = model(train_X)\n",
    "        loss = loss_function(prediction, train_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 50 == 0:\n",
    "            liveloss_updates = {}\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "\n",
    "                def get_metrics(metrics_prefix, metrics_X, metrics_Y):\n",
    "                    metrics_prediction = model(metrics_X)\n",
    "\n",
    "                    return {\n",
    "                        f\"{metrics_prefix}loss\": loss_function(metrics_prediction, metrics_Y),\n",
    "                        f\"{metrics_prefix}accuracy\": torcheval.metrics.functional.multiclass_accuracy(torch.argmax(metrics_prediction, dim=-1), metrics_Y)\n",
    "                    }\n",
    "                \n",
    "                liveloss_updates.update(get_metrics(\"\", train_X, train_Y))\n",
    "                liveloss_updates.update(get_metrics(\"val_\", validation_X, validation_Y))\n",
    "\n",
    "            liveloss_updates = {k: to_numpy(v) for k, v in liveloss_updates.items()}\n",
    "            liveloss.update(liveloss_updates,\n",
    "                            current_step=i+1)\n",
    "            liveloss.send()\n",
    "\n",
    "    return model\n",
    "\n",
    "test_model = train_model(TreeNetwork, epochs=1)\n",
    "del test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XV7wO16oaGmD"
   },
   "outputs": [],
   "source": [
    "base_model = train_model(TreeNetwork, epochs=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZwSPeSF_sMs"
   },
   "source": [
    "## Training Improvements\n",
    "\n",
    "Pick and describe training improvements in each of the following categories.\n",
    "**Your description must be specific to this data set and baseline training process.**\n",
    "You do not need to describe how these methods work in general, and generalities may cost points for making your answer less concise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning:\n",
    "Your training improvements will be sanity checked when models are built with them below.\n",
    "If your training improvement does not improve the validation accuracy, then it will deemed inappropriate for this specific data set and architecture, and you will lose points here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "\n",
    "The baseline model overfits a lot.\n",
    "Make a chart illustrating the overfitting problem in the base model and indicate roughly where the model should have stopped training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe how you will detect overfitting to trigger early stopping.\n",
    "Specific details might include how your detection code avoids triggering on noise.\n",
    "(This might require a finer-grained validation loss chart.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cdbeomfo_sMt"
   },
   "source": [
    "### Initialization\n",
    "\n",
    "Pick a better initialization method for this neural network.\n",
    "What does this initialization method do better than the baseline code?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give an illustrate how your initialization method does better.\n",
    "This might be a chart or some numerical representation of the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate\n",
    "\n",
    "The ADAM optimizer is often touted as needing no hyperparameter tuning except for the learning rate.\n",
    "What is the best improvement that you achieved just changing the learning rate?\n",
    "What was your best learning and was it a material change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a chart showing the improvements (or lack thereof) from optimizing just the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "Pick an appropriate regularization method that we covered in class besides early stopping and learning rate.\n",
    "Explain why you picked this particular method for this problem and model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give an illustrate how your regularization method does better.\n",
    "This might be a chart or some numerical representation of the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training All Combinations\n",
    "\n",
    "Train all 16 combinations of the 4 training improvements.\n",
    "For each combination, plot the loss and accuracy for the training and validation sets during the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: You are strongly encouraged to make a new training function that takes in 4 Boolean parameters controlling the activation of your improvements.\n",
    "Have this function generate the requested charts too.\n",
    "This way, you can write the improvement code once each and just call the training function repeatedly with different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CHANGES HERE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: you may want to save your models with `torch.save` to save retraining time later after receiving the new validation set in a week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Table Comparing the Combinations\n",
    "\n",
    "Fill in the chart below with the final results of each training run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR CHANGES HERE\n",
    "\n",
    "| Early Stopping | Initialization | Learning Rate | Regularization | Training Accuracy | Validation Accuracy | Test Accuracy |\n",
    "|---|---|---|---|---:|---:|---:|\n",
    "| false | false | false | false | | | |\n",
    "| false | false | false | true | | | |\n",
    "| false | false | true | false | | | |\n",
    "| false | false | true | true | | | |\n",
    "| false | true | false | false | | | |\n",
    "| false | true | false | true | | | |\n",
    "| false | true | true | false | | | |\n",
    "| false | true | true | true | | | |\n",
    "| true | false | false | false | | | |\n",
    "| true | false | false | true | | | |\n",
    "| true | false | true | false | | | |\n",
    "| true | false | true | true | | | |\n",
    "| true | true | false | false | | | |\n",
    "| true | true | false | true | | | |\n",
    "| true | true | true | false | | | |\n",
    "| true | true | true | true | | | |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Again\n",
    "\n",
    "Test your models again with the new validation2 data (to be posted 10/13).\n",
    "Use your existing models trained and do not retrain them using the validation2 data.\n",
    "Fill in the table below with your validation2 accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR CHANGES HERE\n",
    "\n",
    "| Early Stopping | Initialization | Learning Rate | Regularization | Validation2 Accuracy |\n",
    "|---|---|---|---|---:|\n",
    "| false | false | false | false | |\n",
    "| false | false | false | true | |\n",
    "| false | false | true | false | |\n",
    "| false | false | true | true | |\n",
    "| false | true | false | false | |\n",
    "| false | true | false | true | |\n",
    "| false | true | true | false | |\n",
    "| false | true | true | true | |\n",
    "| true | false | false | false | |\n",
    "| true | false | false | true | |\n",
    "| true | false | true | false | |\n",
    "| true | false | true | true | |\n",
    "| true | true | false | false | |\n",
    "| true | true | false | true | |\n",
    "| true | true | true | false | |\n",
    "| true | true | true | true | |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your new validation results are poor, you may go back and refine your training improvements, but avoid using validation2 when you do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Your Improvements\n",
    "\n",
    "For each of your training improvements, check if they were used in the model with the best validation2 performance.\n",
    "As best you can, explain why that was the case.\n",
    "It may help to refer to other rows of the validation2 results treating it as an ablation study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Best Model for Auto-Grader Evaluation\n",
    "\n",
    "Use `torch.save` to save your best performing model as \"best.pt\".\n",
    "Check the auto-grader results as soon as possible to confirm that it can load your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: The auto-grader will check this model's accuracy on a withheld test set.\n",
    "Review your results above and tweak your improvements as you feel appropriate.\n",
    "But beware, overfitting on the visible data sets will likely lead to poor performance on the withheld test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
